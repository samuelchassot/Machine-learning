{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from proj1_helpers import *\n",
    "from implementations import *\n",
    "DATA_TRAIN_PATH = 'data/train.csv'\n",
    "y, tX, ids = load_csv_data(DATA_TRAIN_PATH)\n",
    "DATA_TEST_PATH = 'data/test.csv'\n",
    "_, tX_test, ids_test = load_csv_data(DATA_TEST_PATH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_k_indices(y, k_fold, seed):\n",
    "    \"\"\"build k indices for k-fold.\"\"\"\n",
    "    num_row = y.shape[0]\n",
    "    interval = int(num_row / k_fold)\n",
    "    np.random.seed(seed)\n",
    "    indices = np.random.permutation(num_row)\n",
    "    k_indices = [indices[k * interval: (k + 1) * interval]\n",
    "                 for k in range(k_fold)]\n",
    "    return np.array(k_indices)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def map_label_01(y):\n",
    "    y_logistic = []\n",
    "    for elem in y:\n",
    "        if elem == -1:\n",
    "            y_logistic.append(0)\n",
    "        else:\n",
    "            y_logistic.append(1)\n",
    "            \n",
    "    return np.asarray(y_logistic)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cross_validation_least_squares_GD(y, tx, initial_w, max_iters, gammas, k_fold, seed):\n",
    "    \"\"\"Do cross-validation to find the best gamma to use with least_squares_GD\"\"\"\n",
    "    # split data in k fold\n",
    "    k_indices = build_k_indices(y, k_fold, seed)\n",
    "    \n",
    "    mse_tr = []\n",
    "    mse_te = []\n",
    "    \n",
    "    weights = initial_w\n",
    "    \n",
    "    for gamma in gammas:\n",
    "        tr_tmp = []\n",
    "        te_tmp = []\n",
    "        for k in range(k_fold):\n",
    "            # divide the data into training set and testing set depending on k\n",
    "            tr_indice = k_indices[~(np.arange(k_indices.shape[0]) == k)].reshape(-1)\n",
    "            test_tx = tx[k_indices[k]]\n",
    "            test_y = y[k_indices[k]]\n",
    "            train_tx = tx[tr_indice]\n",
    "            train_y = y[tr_indice]\n",
    "            \n",
    "            #Train the set and computes the losses\n",
    "            weights, loss_tr = least_squares_GD(train_y, train_tx, initial_w, max_iters, gamma)\n",
    "            loss_te = compute_loss(mse, test_y, test_tx, weights)\n",
    "            \n",
    "            tr_tmp.append(loss_tr)\n",
    "            te_tmp.append(loss_te)\n",
    "        mse_tr.append(np.mean(tr_tmp))\n",
    "        mse_te.append(np.mean(te_tmp))\n",
    "        \n",
    "    gamma = gammas[np.argmin(mse_te)]\n",
    "    weights_final, loss = least_squares_GD(y, tx, initial_w, max_iters, gamma)\n",
    "        \n",
    "    return mse_tr, mse_te, gamma, weights_final, loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cross_validation_logistic_regression(y, tx, initial_w, max_iters, gammas, k_fold, seed):\n",
    "    \"\"\"Do cross-validation to find the best gamma to use with logistic regression\"\"\"\n",
    "    # split data in k fold\n",
    "    k_indices = build_k_indices(y, k_fold, seed)\n",
    "    \n",
    "    loss_sigmoid_tr = []\n",
    "    loss_sigmoid_te = []\n",
    "    \n",
    "    weights = initial_w\n",
    "    \n",
    "    for gamma in gammas:\n",
    "        tr_tmp = []\n",
    "        te_tmp = []\n",
    "        for k in range(k_fold):\n",
    "            # divide the data into training set and testing set depending on k\n",
    "            tr_indice = k_indices[~(np.arange(k_indices.shape[0]) == k)].reshape(-1)\n",
    "            test_tx = tx[k_indices[k]]\n",
    "            test_y = y[k_indices[k]]\n",
    "            train_tx = tx[tr_indice]\n",
    "            train_y = y[tr_indice]\n",
    "            \n",
    "            #Train the set and computes the losses\n",
    "            weights, loss_tr = logistic_regression(train_y, train_tx, initial_w, max_iters, gamma)\n",
    "            loss_te = calculate_loss_sigmoid(test_y, test_tx, weights)\n",
    "            \n",
    "            tr_tmp.append(loss_tr)\n",
    "            te_tmp.append(loss_te)\n",
    "        loss_sigmoid_tr.append(np.mean(tr_tmp))\n",
    "        loss_sigmoid_te.append(np.mean(te_tmp))\n",
    "        \n",
    "        print(loss_sigmoid_te)\n",
    "        \n",
    "    gamma = gammas[np.argmin(loss_sigmoid_te)]\n",
    "    weights_final, loss_sigmoid = logistic_regression(y, tx, initial_w, max_iters, gamma)\n",
    "        \n",
    "    return loss_sigmoid_tr, loss_sigmoid_te, gamma, weights_final, loss_sigmoid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#least_squares_GD cross-validation\n",
    "max_iters = 200\n",
    "k_fold = 5\n",
    "seed = 42\n",
    "\n",
    "tX_stdrzed, mean, std = standardize(tX)\n",
    "\n",
    "initial_w = np.array([0.4 for i in range(tX_stdrzed.shape[1])])\n",
    "\n",
    "gammas = np.array([0.01, 0.02, 0.03, 0.04, 0.05, 0.06, 0.07, 0.08, 0.09])\n",
    "mse_tr_least_squares_GD, mse_te_least_squares_GD, gamma, weights, loss = \\\n",
    "    cross_validation_least_squares_GD(y, tX_stdrzed, initial_w, max_iters, gammas, k_fold, seed)\n",
    "\n",
    "print(mse_tr_least_squares_GD)\n",
    "print(mse_te_least_squares_GD)\n",
    "print(gamma)\n",
    "print(weights)\n",
    "print(loss)\n",
    "\n",
    "tX_test_stdrzd = (tX_test-mean)/std\n",
    "\n",
    "y_pred = predict_labels(weights, tX_test_stdrzd)\n",
    "OUTPUT_PATH = 'data/output_least_squares_GD.csv'\n",
    "create_csv_submission(ids_test, y_pred, OUTPUT_PATH)\n",
    "\n",
    "#0.697 on AICrowd initial_w = np.array([0.4 for i in range(tX_stdrzed.shape[1])]) \n",
    "#0.693 on AICrowd initial_w = np.array([0.0 for i in range(tX_stdrzed.shape[1])]) even if loss smaller"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[37652.404918522974]\n",
      "[37652.404918522974, 29027.774020060468]\n",
      "[37652.404918522974, 29027.774020060468, 27764.098075652997]\n"
     ]
    }
   ],
   "source": [
    "#logistic_regression cross-validation\n",
    "max_iters = 1000\n",
    "k_fold = 5\n",
    "seed = 42\n",
    "\n",
    "tX_stdrzed, mean, std = standardize(tX)\n",
    "y_logistic = map_label_01(y)\n",
    "        \n",
    "initial_w = np.array([0.5 for i in range(tX_stdrzed.shape[1])])\n",
    "gammas = np.array([0.00000001, 0.0000001, 0.0000005, 0.000001, 0.000005])\n",
    "\n",
    "losses_tr_logistic_regression, losses_te_logistic_regression, gamma, weights, loss = \\\n",
    "    cross_validation_logistic_regression(y_logistic, tX_stdrzed, initial_w, max_iters, gammas, k_fold, seed)\n",
    "\n",
    "print(losses_tr_logistic_regression)\n",
    "print(losses_te_logistic_regression)\n",
    "print(gamma)\n",
    "print(weights)\n",
    "print(loss)\n",
    "\n",
    "tX_test_stdrzd = (tX_test-mean)/std\n",
    "\n",
    "y_pred = predict_labels(weights, tX_test_stdrzd)\n",
    "OUTPUT_PATH = 'data/output_logistic_regression.csv'\n",
    "create_csv_submission(ids_test, y_pred, OUTPUT_PATH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#least_squares_GD cross-validation with cleaned data\n",
    "max_iters = 200\n",
    "k_fold = 5\n",
    "seed = 42\n",
    "\n",
    "tX_stdrzed_cleaned, mean, std = standardize(remove_wrong_columns(tX))\n",
    "\n",
    "initial_w = np.array([0.1 for i in range(tX_stdrzed_cleaned.shape[1])]) \n",
    "gammas = np.array([0.01, 0.05, 0.09, 0.1, 0.2, 0.3])\n",
    "\n",
    "mse_tr_least_squares_GD_clean, mse_te_least_squares_GD_clean, gamma, weights, loss = \\\n",
    "    cross_validation_least_squares_GD(y, tX_stdrzed_cleaned, initial_w, max_iters, gammas, k_fold, seed)\n",
    "\n",
    "print(mse_tr_least_squares_GD_clean)\n",
    "print(mse_te_least_squares_GD_clean)\n",
    "print(gamma)\n",
    "print(weights)\n",
    "print(loss)\n",
    "\n",
    "tX_test_stdrzd_cleaned = (remove_wrong_colums(tX_test)-mean)/std\n",
    "\n",
    "y_pred = predict_labels(weights, tX_test_stdrzd_cleaned)\n",
    "OUTPUT_PATH = 'data/output_least_squares_GD_clean.csv'\n",
    "create_csv_submission(ids_test, y_pred, OUTPUT_PATH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#logistic_regression cross-validation with cleaned data\n",
    "max_iters = 1000\n",
    "k_fold = 5\n",
    "seed = 42\n",
    "\n",
    "tX_stdrzed_cleaned, mean, std = standardize(remove_wrong_columns(tX))\n",
    "y_logistic = map_label_01(y)\n",
    "        \n",
    "initial_w = np.array([0.5 for i in range(tX_stdrzed_cleaned.shape[1])])\n",
    "gammas = np.array([0.00000001, 0.0000001, 0.0000005, 0.000001, 0.00001, 0.0001])\n",
    "\n",
    "losses_tr_logistic_regression_clean, losses_te_logistic_regression_clean, gamma, weights, loss = \\\n",
    "    cross_validation_logistic_regression(y_logistic, tX_stdrzed_cleaned, initial_w, max_iters, gammas, k_fold, seed)\n",
    "\n",
    "print(losses_tr_logistic_regression_clean)\n",
    "print(losses_te_logistic_regression_clean)\n",
    "print(gamma)\n",
    "print(weights)\n",
    "print(loss)\n",
    "\n",
    "tX_test_stdrzd_cleaned = (remove_wrong_columns(tX_test)-mean)/std\n",
    "\n",
    "y_pred = predict_labels(weights, tX_test_stdrzd_cleaned)\n",
    "OUTPUT_PATH = 'data/output_logistic_regression_clean.csv'\n",
    "create_csv_submission(ids_test, y_pred, OUTPUT_PATH)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Graphs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_plots_gammas(tr_losses, te_losses, gammas, save_name, title):\n",
    "    plt.semilogx(gammas, tr_losses, marker=\".\", color='r', label='training error')\n",
    "    plt.semilogx(gammas, te_losses, marker=\".\", color='b', label='test error')\n",
    "    plt.xlabel(\"gamma\")\n",
    "    plt.ylabel(\"error\")\n",
    "    plt.title(title)\n",
    "    plt.legend(loc=2)\n",
    "    plt.grid(True)\n",
    "    plt.savefig(save_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Least squares\n",
    "make_plots_gammas(mse_tr_least_squares_GD, mse_te_least_squares_GD, gammas_lsgd, \\\n",
    "                  \"raw_data_least_squares_GD\", \"Least squares gradient descent raw data\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Logistic regression\n",
    "make_plots_gammas(losses_tr_logistic_regression, losses_te_logistic_regression, gammas_logistic, \\\n",
    "                  \"raw_data_logistic_regression\", \"Logistic regression raw data\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Least squares with cleaned data\n",
    "make_plots_gammas(mse_tr_least_squares_GD_clean, mse_te_least_squares_GD_clean, gammas_lsgd_clean, \\\n",
    "                  \"raw_data_least_squares_GD_clean\", \"Least squares gradient descent cleaned data\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Logistic regression with cleaned data\n",
    "make_plots_gammas(losses_tr_logistic_regression_clean, losses_te_logistic_regression_clean, gammas_logistic_clean, \\\n",
    "                  \"raw_data_logistic_regression_clean\", \"Logistic regression cleaned data\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
