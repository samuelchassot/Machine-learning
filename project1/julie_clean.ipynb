{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from proj1_helpers import *\n",
    "from implementations import *\n",
    "DATA_TRAIN_PATH = 'data/train.csv'\n",
    "y, tX, ids = load_csv_data(DATA_TRAIN_PATH)\n",
    "DATA_TEST_PATH = 'data/test.csv'\n",
    "_, tX_test, ids_test = load_csv_data(DATA_TEST_PATH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_k_indices(y, k_fold, seed):\n",
    "    \"\"\"build k indices for k-fold.\"\"\"\n",
    "    num_row = y.shape[0]\n",
    "    interval = int(num_row / k_fold)\n",
    "    np.random.seed(seed)\n",
    "    indices = np.random.permutation(num_row)\n",
    "    k_indices = [indices[k * interval: (k + 1) * interval]\n",
    "                 for k in range(k_fold)]\n",
    "    return np.array(k_indices)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def map_label_01(y):\n",
    "    y_logistic = []\n",
    "    for elem in y:\n",
    "        if elem == -1:\n",
    "            y_logistic.append(0)\n",
    "        else:\n",
    "            y_logistic.append(1)\n",
    "            \n",
    "    return np.asarray(y_logistic)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cross_validation_least_squares_GD(y, tx, initial_w, max_iters, gammas, k_fold, seed):\n",
    "    \"\"\"Do cross-validation to find the best gamma to use with least_squares_GD\"\"\"\n",
    "    # split data in k fold\n",
    "    k_indices = build_k_indices(y, k_fold, seed)\n",
    "    \n",
    "    mse_tr = []\n",
    "    mse_te = []\n",
    "    \n",
    "    weights = initial_w\n",
    "    \n",
    "    for gamma in gammas:\n",
    "        tr_tmp = []\n",
    "        te_tmp = []\n",
    "        for k in range(k_fold):\n",
    "            # divide the data into training set and testing set depending on k\n",
    "            tr_indice = k_indices[~(np.arange(k_indices.shape[0]) == k)].reshape(-1)\n",
    "            test_tx = tx[k_indices[k]]\n",
    "            test_y = y[k_indices[k]]\n",
    "            train_tx = tx[tr_indice]\n",
    "            train_y = y[tr_indice]\n",
    "            \n",
    "            #Train the set and computes the losses\n",
    "            weights, loss_tr = least_squares_GD(train_y, train_tx, initial_w, max_iters, gamma)\n",
    "            loss_te = compute_loss(mse, test_y, test_tx, weights)\n",
    "            \n",
    "            tr_tmp.append(loss_tr)\n",
    "            te_tmp.append(loss_te)\n",
    "        mse_tr.append(np.mean(tr_tmp))\n",
    "        mse_te.append(np.mean(te_tmp))\n",
    "\n",
    "    gamma = gammas[np.argmin(mse_te)]\n",
    "    weights_final, loss = least_squares_GD(y, tx, initial_w, max_iters, gamma)\n",
    "        \n",
    "    return mse_tr, mse_te, gamma, weights_final, loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cross_validation_logistic_regression(y, tx, initial_w, max_iters, gammas, k_fold, seed):\n",
    "    \"\"\"Do cross-validation to find the best gamma to use with logistic regression\"\"\"\n",
    "    # split data in k fold\n",
    "    k_indices = build_k_indices(y, k_fold, seed)\n",
    "    \n",
    "    loss_sigmoid_tr = []\n",
    "    loss_sigmoid_te = []\n",
    "    \n",
    "    weights = initial_w\n",
    "    \n",
    "    for gamma in gammas:\n",
    "        tr_tmp = []\n",
    "        te_tmp = []\n",
    "        for k in range(k_fold):\n",
    "            # divide the data into training set and testing set depending on k\n",
    "            tr_indice = k_indices[~(np.arange(k_indices.shape[0]) == k)].reshape(-1)\n",
    "            test_tx = tx[k_indices[k]]\n",
    "            test_y = y[k_indices[k]]\n",
    "            train_tx = tx[tr_indice]\n",
    "            train_y = y[tr_indice]\n",
    "            \n",
    "            #Train the set and computes the losses\n",
    "            weights, loss_tr = logistic_regression(train_y, train_tx, initial_w, max_iters, gamma)\n",
    "            loss_te = calculate_loss_sigmoid(test_y, test_tx, weights)\n",
    "            \n",
    "            tr_tmp.append(loss_tr)\n",
    "            te_tmp.append(loss_te)\n",
    "        loss_sigmoid_tr.append(np.mean(tr_tmp))\n",
    "        loss_sigmoid_te.append(np.mean(te_tmp))\n",
    "        \n",
    "    gamma = gammas[np.argmin(loss_sigmoid_te)]\n",
    "    weights_final, loss_sigmoid = logistic_regression(y, tx, initial_w, max_iters, gamma)\n",
    "        \n",
    "    return loss_sigmoid_tr, loss_sigmoid_te, gamma, weights_final, loss_sigmoid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#least_squares_GD cross-validation\n",
    "max_iters = 200\n",
    "k_fold = 5\n",
    "seed = 42\n",
    "\n",
    "tX_stdrzed, mean, std = standardize(tX)\n",
    "\n",
    "initial_w = np.array([0.4 for i in range(tX_stdrzed.shape[1])])\n",
    "\n",
    "gammas_lsgd = np.array([0.01, 0.02, 0.03, 0.04, 0.05, 0.06, 0.07, 0.08, 0.09])\n",
    "mse_tr_least_squares_GD, mse_te_least_squares_GD, gamma, weights, loss = \\\n",
    "    cross_validation_least_squares_GD(y, tX_stdrzed, initial_w, max_iters, gammas_lsgd, k_fold, seed)\n",
    "\n",
    "print(mse_tr_least_squares_GD)\n",
    "print(mse_te_least_squares_GD)\n",
    "print(gamma)\n",
    "print(weights)\n",
    "print(loss)\n",
    "\n",
    "tX_test_stdrzd = (tX_test-mean)/std\n",
    "\n",
    "y_pred = predict_labels(weights, tX_test_stdrzd)\n",
    "OUTPUT_PATH = 'data/output_least_squares_GD.csv'\n",
    "create_csv_submission(ids_test, y_pred, OUTPUT_PATH)\n",
    "\n",
    "#0.697 on AICrowd initial_w = np.array([0.4 for i in range(tX_stdrzed.shape[1])]) \n",
    "#0.693 on AICrowd initial_w = np.array([0.0 for i in range(tX_stdrzed.shape[1])]) even if loss smaller"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[37652.404918522974]\n",
      "[37652.404918522974, 29027.774020060468]\n",
      "[37652.404918522974, 29027.774020060468, 27764.098075652997]\n",
      "[37652.404918522974, 29027.774020060468, 27764.098075652997, 26830.30497283832]\n",
      "[37652.404918522974, 29027.774020060468, 27764.098075652997, 26830.30497283832, 40424.460016898876]\n",
      "[150475.07846440357, 116091.83349352962, 111050.11129959478, 107321.8588723096, 175048.16703055985]\n",
      "[37652.404918522974, 29027.774020060468, 27764.098075652997, 26830.30497283832, 40424.460016898876]\n",
      "1e-06\n",
      "[  0.36107142 -13.33658378  -1.35496582   0.61783235   0.01961971\n",
      "   1.04982336  -0.11726647   0.89216496  -0.57865051   2.93050219\n",
      "   0.07234096   1.13344787   0.04818739  10.01062522   0.50332153\n",
      "   0.46376109  -0.86057156   0.49976145   0.56555557   2.7359336\n",
      "   0.54131802  -0.85535579   0.43301581  -0.12296951   0.11121371\n",
      "   0.12505995  -0.93148483  -0.03097258  -0.05234122  -5.18514794]\n",
      "132212.66176250146\n"
     ]
    }
   ],
   "source": [
    "#logistic_regression cross-validation\n",
    "max_iters = 1000\n",
    "k_fold = 5\n",
    "seed = 42\n",
    "\n",
    "tX_stdrzed, mean, std = standardize(tX)\n",
    "y_logistic = map_label_01(y)\n",
    "        \n",
    "initial_w = np.array([0.5 for i in range(tX_stdrzed.shape[1])])\n",
    "gammas_logistic = np.array([0.00000001, 0.0000001, 0.0000005, 0.000001, 0.000005])\n",
    "\n",
    "losses_tr_logistic_regression, losses_te_logistic_regression, gamma, weights, loss = \\\n",
    "    cross_validation_logistic_regression(y_logistic, tX_stdrzed, initial_w, max_iters, gammas_logistic, k_fold, seed)\n",
    "\n",
    "print(losses_tr_logistic_regression)\n",
    "print(losses_te_logistic_regression)\n",
    "print(gamma)\n",
    "print(weights)\n",
    "print(loss)\n",
    "\n",
    "tX_test_stdrzd = (tX_test-mean)/std\n",
    "\n",
    "y_pred = predict_labels(weights, tX_test_stdrzd)\n",
    "OUTPUT_PATH = 'data/output_logistic_regression.csv'\n",
    "create_csv_submission(ids_test, y_pred, OUTPUT_PATH)\n",
    "\n",
    "#0.739 on AICrowd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.4829444274069787, 0.3785810578920398, 0.37585500287088003, 0.37569930267400325, 0.37556759611875135, 0.6061135886916136]\n",
      "[0.4823999202585222, 0.37856564679284066, 0.37588735835461606, 0.37573361444383624, 0.37560345237880965, 0.6036864256436408]\n",
      "0.12\n",
      "[-0.67353872 -0.01935749  0.08089317  0.10270136 -0.09230546  0.14814314\n",
      "  0.05376114  0.10372283  0.42233461  0.06302186  0.06079259  0.012026\n",
      "  0.0630258   0.06600923  0.06210411  0.06446594 -0.03588135  0.07445922\n",
      " -0.15745303]\n",
      "0.37557229648318674\n"
     ]
    }
   ],
   "source": [
    "#least_squares_GD cross-validation with cleaned data\n",
    "max_iters = 200\n",
    "k_fold = 5\n",
    "seed = 42\n",
    "\n",
    "tX_stdrzed_cleaned, mean, std = standardize(remove_wrong_columns(tX))\n",
    "\n",
    "initial_w = np.array([0.4 for i in range(tX_stdrzed_cleaned.shape[1])]) \n",
    "gammas_lsgd_clean = np.array([0.01, 0.05, 0.1, 0.11, 0.12, 0.128])\n",
    "\n",
    "mse_tr_least_squares_GD_clean, mse_te_least_squares_GD_clean, gamma, weights, loss = \\\n",
    "    cross_validation_least_squares_GD(y, tX_stdrzed_cleaned, initial_w, max_iters, gammas_lsgd_clean, k_fold, seed)\n",
    "\n",
    "print(mse_tr_least_squares_GD_clean)\n",
    "print(mse_te_least_squares_GD_clean)\n",
    "print(gamma)\n",
    "print(weights)\n",
    "print(loss)\n",
    "\n",
    "tX_test_stdrzd_cleaned = (remove_wrong_columns(tX_test)-mean)/std\n",
    "\n",
    "y_pred = predict_labels(weights, tX_test_stdrzd_cleaned)\n",
    "OUTPUT_PATH = 'data/output_least_squares_GD_clean.csv'\n",
    "create_csv_submission(ids_test, y_pred, OUTPUT_PATH)\n",
    "\n",
    "#0.72 on AICrowd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[nan]\n",
      "[nan, 27711.668125686665]\n",
      "[nan, 27711.668125686665, 27440.823026442493]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-28-b98fe04f0a4e>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     12\u001b[0m \u001b[0mlosses_tr_logistic_regression_clean\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlosses_te_logistic_regression_clean\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgamma\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mweights\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m\\\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     13\u001b[0m     cross_validation_logistic_regression(y_logistic, tX_stdrzed_cleaned,\\\n\u001b[0;32m---> 14\u001b[0;31m                                          initial_w, max_iters, gammas_logistic_clean, k_fold, seed)\n\u001b[0m\u001b[1;32m     15\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     16\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlosses_tr_logistic_regression_clean\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-10-fd2d3f83e251>\u001b[0m in \u001b[0;36mcross_validation_logistic_regression\u001b[0;34m(y, tx, initial_w, max_iters, gammas, k_fold, seed)\u001b[0m\n\u001b[1;32m     21\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     22\u001b[0m             \u001b[0;31m#Train the set and computes the losses\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 23\u001b[0;31m             \u001b[0mweights\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mloss_tr\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlogistic_regression\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_y\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_tx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minitial_w\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmax_iters\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgamma\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     24\u001b[0m             \u001b[0mloss_te\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcalculate_loss_sigmoid\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtest_y\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest_tx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mweights\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     25\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Documents/Repos/Machine-learning/project1/implementations.py\u001b[0m in \u001b[0;36mlogistic_regression\u001b[0;34m(y, tx, initial_w, max_iters, gamma)\u001b[0m\n\u001b[1;32m    130\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    131\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0m_\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmax_iters\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 132\u001b[0;31m         \u001b[0mw\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlearning_by_gradient_descent\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mw\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgamma\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    133\u001b[0m         \u001b[0;31m# converge criterion\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    134\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mabs\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mloss\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mprevious_loss\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m<\u001b[0m \u001b[0mthreshold\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Documents/Repos/Machine-learning/project1/implementations.py\u001b[0m in \u001b[0;36mlearning_by_gradient_descent\u001b[0;34m(y, tx, w, gamma)\u001b[0m\n\u001b[1;32m     76\u001b[0m     \u001b[0mReturn\u001b[0m \u001b[0mthe\u001b[0m \u001b[0mupdated\u001b[0m \u001b[0mw\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     77\u001b[0m     \"\"\"\n\u001b[0;32m---> 78\u001b[0;31m     \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcalculate_loss_sigmoid\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mw\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     79\u001b[0m     \u001b[0mgradient\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcalculate_gradient_sigmoid\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mw\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     80\u001b[0m     \u001b[0mw\u001b[0m \u001b[0;34m-=\u001b[0m \u001b[0mgamma\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mgradient\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Documents/Repos/Machine-learning/project1/implementations.py\u001b[0m in \u001b[0;36mcalculate_loss_sigmoid\u001b[0;34m(y, tx, w)\u001b[0m\n\u001b[1;32m     64\u001b[0m     \u001b[0;34m\"\"\"compute the cost by negative log likelihood.\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     65\u001b[0m     \u001b[0msigm_tx_w\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msigmoid\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtx\u001b[0m \u001b[0;34m@\u001b[0m \u001b[0mw\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 66\u001b[0;31m     return - np.sum(y.T @ np.log(sigm_tx_w) \\\n\u001b[0m\u001b[1;32m     67\u001b[0m                     + (1 - y).T @ np.log(1 - sigm_tx_w))\n\u001b[1;32m     68\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "#logistic_regression cross-validation with cleaned data\n",
    "max_iters = 1000\n",
    "k_fold = 5\n",
    "seed = 42\n",
    "\n",
    "tX_stdrzed_cleaned, mean, std = standardize(remove_wrong_columns(tX))\n",
    "y_logistic = map_label_01(y)\n",
    "        \n",
    "initial_w = np.array([0.5 for i in range(tX_stdrzed_cleaned.shape[1])])\n",
    "gammas_logistic_clean = np.array([0.0000001, 0.0000005, 0.000001, 0.000005, 0.00001])\n",
    "\n",
    "losses_tr_logistic_regression_clean, losses_te_logistic_regression_clean, gamma, weights, loss = \\\n",
    "    cross_validation_logistic_regression(y_logistic, tX_stdrzed_cleaned,\\\n",
    "                                         initial_w, max_iters, gammas_logistic_clean, k_fold, seed)\n",
    "\n",
    "print(losses_tr_logistic_regression_clean)\n",
    "print(losses_te_logistic_regression_clean)\n",
    "print(gamma)\n",
    "print(weights)\n",
    "print(loss)\n",
    "\n",
    "tX_test_stdrzd_cleaned = (remove_wrong_columns(tX_test)-mean)/std\n",
    "\n",
    "y_pred = predict_labels(weights, tX_test_stdrzd_cleaned)\n",
    "OUTPUT_PATH = 'data/output_logistic_regression_clean.csv'\n",
    "create_csv_submission(ids_test, y_pred, OUTPUT_PATH)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Graphs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_plots_gammas(te_losses, gammas, save_name, title):\n",
    "    plt.semilogx(gammas, te_losses, marker=\".\", color='b', label='cross-validation test error')\n",
    "    plt.xlabel(\"gamma\")\n",
    "    plt.ylabel(\"error\")\n",
    "    plt.title(title)\n",
    "    plt.legend(loc=2)\n",
    "    plt.grid(True)\n",
    "    plt.savefig(save_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Least squares\n",
    "make_plots_gammas(mse_te_least_squares_GD, gammas_lsgd, \\\n",
    "                  \"raw_data_least_squares_GD\", \"Least squares gradient descent raw data\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Least squares without disturbing gamma\n",
    "make_plots_gammas(mse_te_least_squares_GD[:-1], gammas_lsgd[:-1], \\\n",
    "                  \"raw_data_least_squares_GD_useful\", \"Useful gammas for least squares gradient descent raw data\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Logistic regression\n",
    "make_plots_gammas(losses_te_logistic_regression, gammas_logistic, \\\n",
    "                  \"raw_data_logistic_regression\", \"Logistic regression raw data\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYgAAAEaCAYAAAAL7cBuAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4xLjEsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy8QZhcZAAAgAElEQVR4nO3deXxV1bn/8c8TCAlDRAVLlUFQQcoQpoBGUeOMFUFQUWudFb2Vn1MV4epVHGqt16GtQyvXAbEtg7ZXsdqiV4lKxQEVFURkRkArs4kQCOT5/bF2wiGchAA5OcnJ9/16nVey52fvc85+zl5r77XM3RERESkvLdkBiIhI7aQEISIicSlBiIhIXEoQIiISlxKEiIjEpQQhIiJxKUGIAGaWZ2bLY4bnmFlekmIZZ2b3JGPbiWRmS8zspGTHEcvMLjGz6bsxf63bh0RSgqgmNf3BMTM3s8Nqanv1jbt3dff8vV2PmY0xsz9VQ0i1gj53VZcKx0oJQhLGzBrWp+2KpBoliBpgZgPNbJaZrTezd80sO2baKDNbaGYFZvaFmQ2JmXaYmb1lZhvMbLWZTYrGvx3N8qmZFZrZuXG2GXfZaNrJZvZlNO3RaL4romk7/OI1s/bRL6GG0fClZjY3ineRmV0VM2+emS03s1vM7FvgmSrs/y1mtiJa3zwzO7GCY9jCzF42s+/N7EMzuye2aCCK8Rozmw/Mj8b9zsy+jpb5yMyOiZm/cVSUs87MvgD6ltte2RWhmaXFvE9rzGyyme1f7vhcbGbLomN9azRtAPCfwLnR+/RpBfvWy8w+jo7BJCCz3PTdPn5m1sDM/jPms/WRmbWNpnU2s9fNbG20zLCY9Y0zs8fM7JVouffN7NBo2i4/d9F8V8Z8Rr4ws95x5qnwmEbTnzezb6PP6Ntm1rUqMVZh/1qY2ZToM/EBULZcBftyoZktjWK8tdy0fmY2I3pfvrHwXWpU0bEys/3M7O9mtir63P3dzNpUtv2kc3e9quEFLAFOijO+F/AdcATQALg4mjcjmn4OcBAhWZ8L/AAcGE2bANwaTcsE+ses14HDKokn7rJAS6AAOBtIB24AtgJXRNPHAH+KWU/7aFsNo+HTCV8qA44DNgK9o2l50bp+A2QAjSvbf+Bw4GvgoJhtHVrB/kyMXk2ALtFy08sdj9eB/YHG0bifAy2AhsAvgW+BzGjafcA70fxtgdnA8njvJ3Ad8B7QJor7CWBCuePzP9H+9gA2Az+Jdzzj7FcjYGn0PqRH70sxcM+uPj+VHT/gZuDzaB6L4moBNI2WuTQ6Lr2A1UCXaLlxwBqgXzT9z8DE3fjcnQOsICRcAw4DDt6dYxpNvwzIiqb9FpgVM63CGKuwfxOBydF83aJYp1ewL12AQuDYKI6HCJ/v0n3oAxwZbac9MBe4vqJjFR3/swif4SzgeeDFZJ+7Kj2vJTuAVHlRcYL4A3B3uXHzgOMqWM8sYHD0/3hgLNAmzny7+qLGXRa4CHgvZtiA5VQxQcTZzovAddH/ecAWopPwrvY/Onl8B5wEpFeyLw0IJ83DY8bdw84J4oRdvEfrgB7R/4uAATHThlNxgpgLnBgz7cAontITg8ceZ+AD4Lx4xzNOTMcCKwGLGfcu2xPEHh2/aJ7BcbZ3LvBOuXFPAHdE/48DnoyZ9lPgy9343E0t/TxU9h2p7JjGWW7faLvNdxVjZfsX8znqHDPtXipOELezY3JsSvh87/Q9j6ZfD/zvbhyrnsC6yj6zyX6piCnxDgZ+GV2Grjez9YRfrAcBmNlFMcUH6wm/alpGy44knMA/sHBXzWW7sd2Klj2I8AsLAA+f1K/jLB+XmZ1mZu9Fl+/rCV/OljGzrHL3oqrsv7svIHypxgDfmdlEMzsozmYPIJyMY+OMF/MO48zspqioY0O03eYxsR5Ubv6llez2wcD/xsQ/F9gGtIqZ59uY/zcCzSpZX6yDgBXR+xAvlj09fm2BhRXsyxHl1ncB8ONq2JfKthsvjrjHNCoeuy8qfvqekFhgx89ZRTFWtn/xPkeVve/lvys/EK5cADCzTlEx0bdRnPeWi3EHZtbEzJ6Iiqy+B94G9jWzBpXEkFRKEIn3NfArd9835tXE3SeY2cGEookRQAt335dQ1GEA7v6tu1/p7gcBVwGPWxXviqhk2W8IX2IAzMxihwlFXE1ihn8cM28G8FfgAaBVFO+rpfGWbrqq+x/F+Rd370/4YjuheKq8VYRL+9jy2rZx5ivbtoX6hpHAMGC/KNYNMbHucByAdnHWF7sPp5Xbh0x3X1HJMjvFVIFvgNbR+xAvlj09fl8Tv3z9a+Ctcutr5u7/UYV9qYqKthtvvoqO6c+AwYQro+aEqzTY8XNW2Xor2r/Sz1FV3/fy35UmhGKiUn8AvgQ6uvs+hPqmymL8JaHI74ho/mN3Y7+SQgmieqWbWWbMqyEhAVxtZkdY0NTMTjezLMIlqxM+uJjZpYQrCKLhc2IqsdZF85ZEw/8GDqkokEqWfQXoamZDo/iuZcdfj7OAY82snZk1B0bHTGtEKItdBWw1s9OAU3ZxTCrcfzM73MxOiBJPEbApZv/KuPs24G/AmOhXWGdCUVllsggng1VAQzO7HdgnZvpkYHRUcdgG+H+VrOuPwK+ihI6ZHWBmg3ex/VL/BtqbWUXftRlRnNeaWbqZDSWUrZfa0+P3JHC3mXWMlss2sxbA34FOFipf06NXXzP7yW7sT4Wfu2i7N5lZn2i7h5Uet3IqO6ZZhHqcNYQfK/dWMTaoZP/ifI66EOp0KvICMNDM+luofL6LHc+ZWcD3QGH0mSyfZMsfqyzCe7TeQoX8HbuxX0mhBFG9XiV8AEpfY9x9JnAl8CjhRL0AuATA3b8AHiScJP4NdAf+FbO+vsD7ZlYITCGU7S6Kpo0Bno0uo4exs7jLuvtqQkXifYQvYMfYbbr768Ak4DPgI8IXrnRaASGhTI725WfRuitU2f4Tks19hErEb4EfsWNCijWC8GvyW+A5QiX85ko2PRX4J/AVoRihiB2LFu6Mxi8GXovWWZHfEfbzNTMrIFSuHlHJ/LGej/6uMbOPy0909y3AUMIxWUsoQ/9bzPQ9PX4PEd6n1wgnsacIlfcFhKR+HqHu41u231RQFWOo5HPn7s8DvwL+QrgZ4kXCjQDlVXZMxxPemxXAF9G0KqnC/o0gFEd9S6jLeKaSdc0Bron25RvC8V8eM8tNhO9AASGRTyq3ijHseKx+S7iRYXW0T/+s6n4li+1Y9Cn1kZnlEypSn0x2LFVlZr8Bfuzulf0CFJG9oCsIqRMs3NueHRVb9AMuB/432XGJpDI9cSp1RRahWOkgQnHcg8BLSY1IJMWpiElEROJSEZOIiMSlBCEiInGlTB1Ey5YtvX379nu8/A8//EDTpk2rLyARqZfq2rnko48+Wu3uB8SbljIJon379sycOXOPl8/PzycvL6/6AhKReqmunUvMrMLmRlTEJCIicSlBiIhIXEoQIiISV8rUQcRTXFzM8uXLKSoq2uW8zZs3Z+7cuTUQldRXmZmZtGnThvT09GSHIlIlKZ0gli9fTlZWFu3bt2fH1pR3VlBQQFZWVg1FJvWNu7NmzRqWL19Ohw4dkh2OSJWkdBFTUVERLVq02GVyEEk0M6NFixZVupoV2R0zZsCvfx3+VreUvoIAlByk1tBnUarbjBlw/PFQXAwZGfDGG5CbW33rT+gVhJkNMLN5ZrbAzEZVMM8wM/vCQreYf4kZf7GZzY9eatI5gfLz8xk4cCAAU6ZM4b777os7X7Nmlfc8uX79eh5//PGy4ZUrV3L22WdXS4y//e1v2bhx4x4t++KLL/LFF19USxwitUl+PmzeDCUlsGVLGK5OCUsQFvpZfQw4DegCnB/14BQ7T0dCBydHu3tXQv+6xPS2dAShd607zGy/RMWaTFu3bk12CDsYNGgQo0bFzeW7VD5BHHTQQbzwwgvVElcyE0T596iq71lte28l9eTlQVp0Fm/UKAxXp0ReQfQDFkS9mG0BJhL6mY11JfCYu68DcPfvovGnAq+7+9po2uvAgATGWqa6y/PGjx9PdnY2PXr04MILLwTgkksu4eqrr+aII45g5MiRrF27ljPPPJPs7GyOPPJIPvvsMwDeeustevbsSc+ePenVqxcFBQV88803HHvssfTs2ZNu3brxzjvv7LTNI488kjlz5pQN5+XlMXPmTD744ANyc3Pp1asXRx11FPPmzdtp2XHjxjFixAgAFi9eTG5uLt27d+e2224rm6ewsJATTzyR3r170717d156KbS6PWrUKBYuXEjPnj25+eabWbJkCd26hR5Ui4qKuPTSS+nevTu9evVi2rRpZdsbOnQoAwYMoGPHjowcOXKnmH7/+9+zcuVKjj/+eI4//ngAXnvtNXJzc+nduzfnnHMOhYWFZTF06dKF7OxsbrrpJt59912mTJnCzTffTM+ePVm4cOEO6161ahVnnXUWffv2pW/fvvzrX6FzvTFjxnDhhRdy9NFHc+GFFzJu3DgGDRrECSecwIknnoi7c/PNN9OtWze6d+/OpEmhM7H8/HyOOeYYBg0aRJcuO/weEql2ublw2GHQuXP1Fy8B4e6KRLyAs4EnY4YvBB4tN8+LwP2ELi/fAwZE428CbouZ77+AmyrbXp8+fby8L774ouz/665zP+64il/9+xd7z57uaWnuEP727Fn5Mtddt9MmdzB79mzv2LGjr1q1yt3d16xZ4+7uF198sZ9++um+detWd3cfMWKEjxkzxt3d33jjDe/Ro4e7uw8cONCnT5/u7u4FBQVeXFzsDzzwgN9zzz3u7r5161b//vvvd9ruQw895Lfffru7u69cudI7derk7u4bNmzw4uJid3d//fXXfejQoe7uPm3aND/99NPd3f2ZZ57xa665xt3dzzjjDH/22Wfd3f3RRx/1pk2burt7cXGxb9iwwd3dV61a5YceeqiXlJT44sWLvWvXrmVxxA4/8MADfumll7q7+9y5c71t27a+adMmf+aZZ7xDhw6+fv1637Rpk7dr186XLVu20z4dfPDBZcdx1apVfswxx3hhYaG7u993331+5513+urVq71Tp05eUlLi7u7r1q0rO97PP/983Pfo/PPP93feecfd3ZcuXeqdO3d2d/c77rjDe/fu7Rs3biw7Lq1bty57D1944QU/6aSTfOvWrf7tt99627ZtfeXKlT5t2jRv0qSJL1q0KO72Yj+TkpqmTZtWo9vr3Nl92LA9Xx6Y6RWcV5NdSd2Q0CdyHtAGeNvMuld1YTMbDgwHaNWqFfnlCuCaN29OQUEBAFu2ZLBtW8UXTO6wbt02SkrSAKOkxFm3roRmzSruL2PLlhIKCiruFvnVV19l8ODBZGRkUFBQQHp6OgUFBRQXFzNw4MCyIpO3336b5557joKCAvr27cvq1atZsWIFOTk5XHfddQwbNoxBgwbRunVrunbtyi9+8QsKCwsZOHAg2dnZZftY6qc//SlnnnkmN910E+PHj2fQoEEUFBSwYsUKRo4cycKFCzEziouLKSgoYOPGjWzdupWCggKKiorYsmULBQUFTJ8+nXHjxlFQUMCZZ57JLbfcUhb/qFGjePfdd0lLS2PFihUsXLiQoqIiSkpKyuIpLCwsG87Pz+eqq66ioKCA1q1b06ZNGz755BOKioo49thjSUtLo7i4mE6dOjF37lz23Xffcu+PU1hYSEZGBm+++SZz5swhN/q5tGXLFvr160daWhqNGjXioosuYsCAAQwYMKAs3k2bNu10nABef/11Zs+eXTa8YcMGvvnmGzZv3sypp566w3HJy8srew/ffPNNhgwZwsaNG2nSpAlHHXUUb7/9NllZWfTp04eWLVvG3V5RUdFOn1NJLYWFhTX6Hq9bdyTff7+O/PydSwT2ViITxAqgbcxwm2hcrOXA++5eDCw2s68ICWMFIWnELptffgPuPhYYC5CTk+PlG8iaO3du2bMNMUXjcRUUFDB7dhYnnhgqexo1MiZMaFCFS7ZGFU7JzMykUaNGOz1fkZ6eTsuWLcvGp6Wl0axZs7JhMyMrK4s77riDoUOH8uqrr3LqqacydepUBgwYwPTp03nllVe45ppruPHGG8nKyuLOO+8E4MknnyQnJ4cDDjiAxYsX89JLL/HHP/6RrKwsfvOb33DyySfz8ssvs2TJEvLy8sjKyqJJkyY0bNiQrKysHWI2M/bZZx8aNmxYeiVHVlYW48aNY8OGDXzyySekp6fTvn17GjZsSLNmzUhLSyvbj9jhhg0b0qRJk7JpDRo0oGnTpmRmZu6w7xkZGXGPmZmVzde4cWNOOeUUJkyYsNMxnzlzJm+88QYvvPACTz31FG+++Sbp6ek0btw47nMu7s4HH3xAZmbmDuMzMjJ2iCszM5N99923bLhRo0ZkZmaWDZduo0mTJuyzzz4VPlOTmZlJr1694k6T1FDTjfVt2waHHHIgeXkHVvu6E1kH8SHQ0cw6mFkj4DxgSrl5XiRKBGbWEugELAKmAqeY2X5R5fQp0biEys0N5Xh331095XknnHACzz//PGvWrAFg7dq1cec75phj+POf/wyED1fLli3ZZ599WLhwId27d+eWW26hb9++fPnllyxdupRWrVpx5ZVXcsUVV/Dxxx8zZMgQZs2axaxZs8jJyQHg3HPP5f7772fDhg1kZ2cD4ddx69atgVD2vytHH300EydOBCiLr3Q9P/rRj0hPT2fatGksXRoag8zKyor7q7n8Pn711VcsW7aMww8/fJcxlIpd95FHHsm//vUvFixYAITmlb/66isKCwvZsGEDP/3pT3n44Yf59NNPdxnXKaecwiOPPFI2PGvWrCrFc8wxxzBp0iS2bdvGqlWrePvtt+nXr1+V90ekumzcCE2aJGbdCUsQ7r4VGEE4sc8FJrv7HDO7y8wGRbNNBdaY2RfANOBmd1/j7muBuwlJ5kPgrmhcwuXmwujR1VPZ07VrV2699VaOO+44evTowY033hh3vjFjxvDRRx+RnZ3NqFGjePbZZ4Fw5063bt3Izs4mPT2d0047jfz8fHr06EGvXr2YNGkS1113Xdx1nn322UycOJFhw4aVjRs5ciSjR4+mV69eVbrD5ne/+x2PPfYY3bt3Z8WK7Rd/F1xwATNnzqR79+6MHz+ezp07A9CiRQuOPvpounXrxs0337zDun7xi19QUlJC9+7dOffccxk3bhwZGRm7jKHU8OHDGTBgAMcffzwHHHAA48aN4/zzzyc7O5vc3Fy+/PJLCgoKyord+vfvz0MPPQTAeeedx3//93/Tq1evnSqpf//73zNz5kyys7Pp0qULf/zjH6sUz5AhQ8puPjjhhBO4//77+fGPf1zl/RGpDu6JTRAp0yd1Tk6Ol+8PYu7cufzkJz+p0vJqakNqwu58JqVuqskipk2bQnK47z645ZY9W4eZfeTuOfGmpXRTGyIiqaz00aA6V8QkIiKJpQQhIiJxKUHspVSpY5G6T59FqW5KEHshMzOTNWvW6IspSedRfxDln7cQ2RuJThDJfpI6odq0acPy5ctZtWrVLuctKirSl1cSqrRHOZHqogSxF9LT06vce1d+fr6ecBWROkVFTCIiEpcShIiIxKUEISIicW3aFP4qQYiIyA50BSEiInGVJohE3YCpBCEiUkeVtuRqlpj1K0GIiNRRiWzqG5QgRETqLCUIERGJSwlCRETiUoIQEZG4lCBERCQuJQgREYlLCUJEROLauBEaN07c+pUgRETqKF1BiIhIXEoQIiISlxKEiIjsZNs22LxZCUJERMpJdF8QoAQhIlInJbovCFCCEBGpk5QgREQkLiUIERGJSwlCRETiUoIQEZG4lCBERCQuJQgREYlLCUJEROKq8wnCzAaY2TwzW2Bmo+JMv8TMVpnZrOh1Rcy0bTHjpyQyThGRuqYmEkTDRK3YzBoAjwEnA8uBD81sirt/UW7WSe4+Is4qNrl7z0TFJyJSl9X1K4h+wAJ3X+TuW4CJwOAEbk9EpN7YuBEaNID09MRtI2FXEEBr4OuY4eXAEXHmO8vMjgW+Am5w99JlMs1sJrAVuM/dXyy/oJkNB4YDtGrVivz8/D0OtrCwcK+WFxGBmjuXzJt3KBkZB/LWW9MTto1EJoiqeBmY4O6bzewq4FnghGjawe6+wswOAd40s8/dfWHswu4+FhgLkJOT43l5eXscSH5+PnuzvIgI1Ny5ZOJEyMoiodtKZBHTCqBtzHCbaFwZd1/j7pujwSeBPjHTVkR/FwH5QK8ExioiUqckurMgSGyC+BDoaGYdzKwRcB6ww91IZnZgzOAgYG40fj8zy4j+bwkcDZSv3BYRqbdqIkEkrIjJ3bea2QhgKtAAeNrd55jZXcBMd58CXGtmgwj1DGuBS6LFfwI8YWYlhCR2X5y7n0RE6q06nSAA3P1V4NVy426P+X80MDrOcu8C3RMZm4hIXVbXi5hERCRBlCBERCQuJQgREYlLCUJEROJSghARkbiUIEREZCfuShAiIhJHcTFs26YEISIi5dREU9+gBCEiUucoQYiISFxKECIiEpcShIiIxKUEISIicSlBiIhIXEoQIiISV2mCaNw4sdtRghARqWM2bQp/dQUhIiI7UBGTiIjEpQQhIiJxqQ5CRETi2rgRGjWChg0Tux0lCBGROqYmmvoGJQgRkTpHCUJEROJSghARkbiUIEREJC4lCBERiUsJQkRE4lKCEBGRuJQgREQkLiUIERGJSwlCRETiUoIQEZGduCtBiIhIHEVF4a8ShIiI7KCm+oKABCcIMxtgZvPMbIGZjYoz/RIzW2Vms6LXFTHTLjaz+dHr4kTGKSJSV9RkgkhYa+Jm1gB4DDgZWA58aGZT3P2LcrNOcvcR5ZbdH7gDyAEc+Chadl2i4hURqQtq1RWEmTUwsxv2YN39gAXuvsjdtwATgcFVXPZU4HV3XxslhdeBAXsQg4hISqlVVxDuvs3Mzgce3s11twa+jhleDhwRZ76zzOxY4CvgBnf/uoJlW5df0MyGA8MBWrVqRX5+/m6GuF1hYeFeLS8iAok/l3z++T5Ab+bP/5T8/MQWqlS1iOlfZvYoMAn4oXSku3+8l9t/GZjg7pvN7CrgWeCEqi7s7mOBsQA5OTmel5e3x4Hk5+ezN8uLiEDizyXFxeFvbm4Pjj46YZsBqp4gekZ/74oZ51R+Ml8BtI0ZbhON274C9zUxg08C98csm1du2fwqxioikrJqVRETgLsfvwfr/hDoaGYdCCf884Cfxc5gZge6+zfR4CBgbvT/VOBeM9svGj4FGL0HMYiIpJRalyDMrDnhrqJjo1FvAXe5+4aKlnH3rWY2gnCybwA87e5zzOwuYKa7TwGuNbNBwFZgLXBJtOxaM7ubkGSItrV2t/dORCTF1LoEATwNzAaGRcMXAs8AQytbyN1fBV4tN+72mP9HU8GVgbs/HW1XREQitTFBHOruZ8UM32lmsxIRkIiIVKxWPQcR2WRm/UsHzOxoYFNiQhIRkYqUJojMzMRvq6pXEFcD46O6CIB1gJq/EBGpYaUtuZolflu7TBBmlgYc7u49zGwfAHf/PuGRiYjITmqqqW+oQhGTu5cAI6P/v1dyEBFJnlqVICL/Z2Y3mVlbM9u/9JXQyEREZCc1mSCqWgdxbvT3mphxDhxSveGIiEhlalWCiOogfu7u/6qBeEREpBK1KkG4e0nUUF+vGognKf7wB5g5sx0ZGZCbm+xoREQqtnEj7LNPzWyrqnUQb5jZWWY1cWNVzXr+efjFL+Dppztw3HGgFr9FpDbbuBEaN66ZbVU1QVwFTAY2m9n3ZlZgZilxN9P8+ZCWBmAUF8PAgXDvvbB+fbIjExHZWW28i6k5oSG9e9x9H6AroSvROu/44yEjA9LSSsjIgG7d4NZboV07GDkSVq5MdoQiItvVxgTxGHAkcH40XAA8mpCIalhuLrzxBlx22RKmTYP33oNPPoHTT4cHH4QOHWD48HClISKSbLUxQRzh7tcARQBRP9GNEhZVDcvNhQsuWFZWQd2zJ0yYAF99BZdfDuPHw+GHw7Bh8NFHyY1VROq32pggis2sAeHZB8zsAKAkYVHVEoceCo8/DkuXwqhRMHUq5OTAySeHqw73ZEcoIvXJ1q2wZUvtSxC/B/4X+JGZ/QqYDtybsKhqmVatQsX1smXwm9/A7Nlw0knQrx/89a+wbVuyIxSR+mBT1IZ2rUoQ7v5nQntMvwa+Ac509+cTGVht1Lx5qLhevBieeCLc6XT22dClCzz1FGzenOwIRSSV1WRfEFD1Kwjc/Ut3f8zdH3X3ubteInVlZoaK6y+/hMmToWlTuOIKOOSQULFdUJDsCEUkFdXaBCE7a9AAzjknVFy/9hp07gw33RRukb3tNvjuu2RHKCKpRAmiDjLbXnH9/vtwwgmhzuLgg2HECFiyJNkRikgqUIKo40orrr/4An72Mxg7Fg47DH7+c/j882RHJyJ1mRJEiujcOVRcL1oE118PL74I2dmhKY/p05MdnYjURUoQKaZNG3jggXCL7N13hyKoY46B/v3h73+HkpR/mkREqkutvM1V9t7++4eK66VL4ZFHYPlyOOOMcFXx3HNQXJzsCEWkttMVRIpr0iRUXM+fHxIDwEUXhXqKRx7Z/gEQESlPCaKeSE8PFdeffQYvvwxt28K114Y7n+6+G9auTXaEIlLbKEHUM2lp2yuu33kHjjwSbr89PEvxy1+GoigREVCCqNf69w9XE599BkOGwO9+F57Ovvzy8NS2iNRvGzeGB3TT02tme0oQtVD37qF+YsECuOoq+MtfQntPQ4fCBx8kOzoRSZbSpr5rqvNnJYharH37UHG9dGno5W7aNDjiiPCk9muvqblxkfqmJvuCACWIOuFHPwoV18uWhcYA582DU0+FPn1CY4FqblykflCCkAplZcGNN4ans596Cn74Ac49N/R2N3YsFBUlO0IRSSQlCNmljAy47LLQ3tNf/wr77RfqKjp0CB0abdiQ7AhFJBGUIKTKGjTYXnH9xhuhcnvUqHCL7OjR8O23yY5QRKpTSiUIMxtgZvPMbIGZjapkvrPMzM0sJxpub2abzGxW9PpjIuOs68y2V1zPnAkDBoQrifbt4T/+A5DOhVUAABEhSURBVBYuTHaEIlIdUiZBmFkD4DHgNKALcL6ZdYkzXxZwHfB+uUkL3b1n9Lo6UXGmmj59YNKkUJF98cXw9NPQqROcfz7MmpXs6ERkb6RMggD6AQvcfZG7bwEmAoPjzHc38BtAVazVqGPH0G/2kiWhl7tXXoFeveC00+Ctt3SLrEhdlEoJojXwdczw8mhcGTPrDbR191fiLN/BzD4xs7fM7JgExpnSDjwwFDctWxZ6ufv4Y8jLg6OOCn1UqLlxkbqjphNEw5rb1I7MLA14CLgkzuRvgHbuvsbM+gAvmllXd/++3DqGA8MBWrVqRX5+/h7HU1hYuFfL1wW5udC7dxr//OePmTSpLUOGNKZdux84//yvOfHEf5OerssKkb2VyHNJQUF/1qz5hvz8GqpYdPeEvIBcYGrM8GhgdMxwc2A1sCR6FQErgZw468qPNz721adPH98b06ZN26vl65riYve//MW9Rw93cG/Txv3hh90LCpIdmUjdlqhzSUmJe4MG7rfeWr3rBWZ6BefVRBYxfQh0NLMOZtYIOA+YEpOYNrh7S3dv7+7tgfeAQe4+08wOiCq5MbNDgI7AogTGWu80bBgqrj/5BP7xDzj0ULjhhtDc+JgxsHp1siMUkVjFxaHVhJSog3D3rcAIYCowF5js7nPM7C4zG7SLxY8FPjOzWcALwNXurh4SEsAs3Babnw/vvhu6Q73zzpAorr8+1F2ISPLVdFPfkODnINz9VXfv5O6HuvuvonG3u/uUOPPmufvM6P+/untXD7e49nb3lxMZpwS5uaHies4cOOcceOyxcGVx8cVhnIgkT8olCKmbunSBcePCA3YjRsALL0C3bjB4MMyYkezoROonJQipVdq1g4cfDsVMY8aEXu+OOgqOOy7UW+hZCpGaowQhtVKLFnDHHSFR/Pa3oTXZn/4UevYMnRlt3ZrsCEVSnxKE1GpNm8J114Wip3Hjwl0VF1wQmvJ4/HHYtCnZEYqkLiUIqRMaNQoV17Nnh0rtVq3gmmtC44D33gvr1yc7QpHUU5ogGjeuuW0qQcgeS0sLFdfvvhvad+rTJ3SN2q4djBwJK1cmO0KR1KErCKmTzODYY+HVV8ODdwMHhq5RO3SA4cNh/vxkRyhS9ylBSJ1XWnE9fz5cfjmMHx+6RB02DD76KNnRidRdShCSMg45JFRcL10aermbOhVycuDkk0Pvd7pFVmT3KEFIymnVKlRcL1sWmh2fPRtOOgn69Qv9aW/bluwIReoGVVJLymrePFRcL14MY8eGO53OPjs8tf3UU7B5c7IjFKndNm4MdxA2rMFOGpQgpEZlZsKVV8KXX8LkydCsGVxxRSiSevBBKChIdoQitVNNdxYEShCSJA0ahAYBZ86E116Dzp1D16jt2sFtt8F33yU7QpHaRQlC6h2z7RXXH3wAJ5wQ6iwOPjg0FLhkSbIjFKkdlCCkXuvbN1Rcz50bmvAYOxYOOwx+/nP4/PNkRyeSXEoQIoTnJp58MlRoX399aM4jOzs8gDd9erKjE0kOJQiRGK1bwwMPhFtk774b3n8/9HjXvz/8/e9QUpLsCEVqjhKESBz77x8qrpcuhUcegeXL4YwzwlXFc8+FVmVFUp0ShEglmjQJFdfz58Of/hQquC+6KNRTPPLI9geJRFKREoRIFaSnh0rszz4LRU3t2sG114Y7n+6+G9auTXaEItVPCUJkN5jB6afDO++E15FHwu23h4Txy1+GoiiRVKEEIbKH+veHl18OVxVDhsDvfheezr788vDUtkhdpwQhspe6dw8V1wsWwFVXwYQJob2noUPDg3gidVFJSejSVwlCpBq0bx8qrpcuDXdATZsGRxwRntR+7TU1Ny51S1FR+KsEIVKNDjgA7rorPEvx4IMwbx6cemroHnXyZDU3LnVDMvqCACUIqSeysuDGG2HRotC8+MaNcO654antsWO3/0ITqY2UIERqQEYGXHYZzJkT2n3af/9QV9GhQ+jQaMOGZEcosjMlCJEa1KBBqLh+//3Qkmx2dugatV07GD0avv022RGKbKcEIZIEZqHieupU+OgjGDAgXEm0bw//8R+wcGGyIxRRghBJut69YdKkUJF98cXw9NPQqROcfz7MmpXs6KQ+27Qp/FWCEEmyjh3hiSdCZ0U33QSvvAK9esFpp8Fbb+kWWal5uoIQqWUOPDAUNy1bBr/+NXz8MeTlwVFHhT4q1Ny41BQlCJFaat99QwX2kiXwhz+E/rKHDIGuXWHcONiyJdkRSqpTghCp5Ro3hquvDnUUEyaEW2YvvRQOPRR++1soLEx2hJKqlCBE6oiGDeG88+CTT+Af/wgJ4oYbQnPjY8bA6tXJjlBSTUomCDMbYGbzzGyBmY2qZL6zzMzNLCdm3OhouXlmdmoi4xTZE2bhttj8fHj33dAd6p13hkRx/fWh7kKkOpQmiMzMmt1uwhKEmTUAHgNOA7oA55tZlzjzZQHXAe/HjOsCnAd0BQYAj0frE6mVcnNDxfWcOTBsGDz2WLiyuPjiME5kb5Q29W1Ws9tN5BVEP2CBuy9y9y3ARGBwnPnuBn4DxLaGMxiY6O6b3X0xsCBan0it1qULPPNMeMBuxAh44QXo1g0GD4YZM5IdndRVyegLAqBhAtfdGvg6Zng5cETsDGbWG2jr7q+Y2c3lln2v3LKty2/AzIYDwwFatWpFfn7+HgdbWFi4V8uLlDd4MOTlNeTFF1vzt7+1YcqUdLKz1/Ozny2jX7+1Nf5rUGpGIs4lixYdToMG+5Gf/96uZ65GiUwQlTKzNOAh4JI9XYe7jwXGAuTk5HheXt4ex5Ofn8/eLC9SkcGD4dFH4ckn4cEH92XUqH3JzoZbbgnFUQ2T9i2UREjEueQPf4D99qPGz1GJLGJaAbSNGW4TjSuVBXQD8s1sCXAkMCWqqN7VsiJ1StOmcN11oae7ceNg61a44ILQlMfjj29vSkEknmQVMSUyQXwIdDSzDmbWiFDpPKV0ortvcPeW7t7e3dsTipQGufvMaL7zzCzDzDoAHQF1GCl1XqNGoeL688/hpZegVSu45prQOOC998L69cmOUGqjlEsQ7r4VGAFMBeYCk919jpndZWaDdrHsHGAy8AXwT+Aad1ffX5Iy0tJg0KBwe+xbb4Ue7m69NTQ3PnIkrFyZ7AilNtm4MTyoWdMS+hyEu7/q7p3c/VB3/1U07nZ3nxJn3rzo6qF0+FfRcoe7+z8SGadIspjBscfCq6+GFmMHDgxdo3boAMOHw/z5yY5QaoOUu4IQkd3Towf85S8hKVx+OYwfH7pEHTYs9FUh9ZcShIgAcMghoeJ66dLQu91rr0FODpx8cuj9Ts2N1z9KECKyg1at4Fe/Ck123H8/zJ4NJ50E/fqF/rS3qVau3lCCEJG49tkHbr4ZFi+GsWPDnU5nnx2e2n7qKdi8OdkRSqIpQYhIpTIz4cor4csvYfJkaNYMrrgiFEk9+CAUFCQ7QkmErVtDnyNKECKySw0awDnnwMyZ8Prr8JOfhK5R27WD224LHRpJ6khWf9SgBCFSZ5mFOon/+z/44AM48cTwsN3BB4eGApcsSXaEUh2S1RcEKEGIpIS+fUPLsXPnhiY8xo6Fww6Dn/88PLUtdZcShIhUi8MPD40CLl4cOi166SXIzg4P4E2fnuzoZE8oQYhItWrdGh54IDxLcffd8P77oce7/v3h73+HkpJkRyhVpQQhIgmx//6h4nrp0tDk+PLlcMYZ4ariueeguDjZEcquKEGISEI1aRJajZ0/H/70p1DBfdFFoZ7ixhvh2mthwoRQNLVyJaxZAz/8EG6xlORKZoJQVyUi9Uh6eqjE/tnPQgOB//mf8PDDYdojj8RfJi0NMjLCKzNz+/+xr3jjEzVvWj37WasEISI1ygxOPx0++yw04VFSEk68Q4eGW2c3b97xVVS087jY8UVFsGFDxfMWFVVfG1Lp6clPUqXj09PZoevYGTPgz39uR0YG5OZWvh8zZkB+PuTlVT7vp5+Gv/PmhaLBmqQEIVKP5eWFk92WLaEzoxtv3PWJbU+4h+Kq3Uk6ezOuoABWr6543i1bqm/fYq9sNmwA9w489RS0aROedm/QYOfXDz/AnDnbE3NODrRosX16Wlr4u24dTJsWtnPRRWGdiXh/KqIEIVKP5eaGFmKr8kt2b5iFX9vp6eGkmWwlJSFJ7O6VUmXjZswIDyxCuKTYd99w2/G2bTu/vvtu+51kJSWh3qekJEwr/bttG6xatX2+4uLwPilBiEiNyc2t2ZNObZCWFoqIMjOrb50zZoSn2TdvLiEjI40nnqj4uJbOW3rlNnly/HnLz5eXV33xVoUShIhINSi9Gnv66SVcdtkhlSbdql651dQVXkWUIEREqkluLmzevIzc3EOqNG9VTvjJvMKrZzeMiYhIVSlBiIhIXEoQIiISlxKEiIjEpQQhIiJxKUGIiEhc5tXVQEqSmdkqYGk02BzYsJuraAmsrtag6qc9Ofa1TW3Zh5qMI1Hbqq717u169nT5+nAuOdjdD4g3IWUSRCwzG+vuw3dzmZnunpOomOqLPTn2tU1t2YeajCNR26qu9e7tevZ0+fp+LknVIqaXkx1APZYKx7627ENNxpGobVXXevd2PXu6fG35LCRFSl5B7IlUyvoikjypdC5J1SuIPTE22QGISEpImXOJriBERCQuXUGIiEhcShAiIhKXEoSIiMSlBLELZnammf2PmU0ys1OSHY+I1E1mdoiZPWVmLyQ7lqpK6QRhZk+b2XdmNrvc+AFmNs/MFpjZqMrW4e4vuvuVwNXAuYmMV0Rqp2o6lyxy98sTG2n1Sum7mMzsWKAQGO/u3aJxDYCvgJOB5cCHwPlAA+DX5VZxmbt/Fy33IPBnd/+4hsIXkVqims8lL7j72TUV+95I6S5H3f1tM2tfbnQ/YIG7LwIws4nAYHf/NTCw/DrMzID7gH8oOYjUT9VxLqmLUrqIqQKtga9jhpdH4yry/4CTgLPN7OpEBiYidcpunUvMrIWZ/RHoZWajEx1cdUjpK4jq4O6/B36f7DhEpG5z9zWEusw6oz5eQawA2sYMt4nGiYjsjpQ/l9THBPEh0NHMOphZI+A8YEqSYxKRuiflzyUpnSDMbAIwAzjczJab2eXuvhUYAUwF5gKT3X1OMuMUkdqtvp5LUvo2VxER2XMpfQUhIiJ7TglCRETiUoIQEZG4lCBERCQuJQgREYlLCUJEROJSghARkbiUIEREJC4lCJFKmNl/RR3CTDezCWZ2k5ldaWYfmtmnZvZXM2sSzTvOzP5gZu+Z2SIzy4s6mplrZuNi1lloZv9tZnPM7P/MrJ+Z5UfLDIrmaW9m75jZx9HrqCQdAqnHlCBEKmBmfYGzgB7AaUBONOlv7t7X3XsQmliI7SVsPyAXuIHQLs/DQFegu5n1jOZpCrzp7l2BAuAeQqczQ4C7onm+A052996EngzVorDUODX3LVKxo4GX3L0IKDKzl6Px3czsHmBfoBmhLZ5SL7u7m9nnwL/d/XMAM5sDtAdmAVuAf0bzfw5sdvfiaJn20fh04NEoqWwDOiVoH0UqpAQhsvvGAWe6+6dmdgmQFzNtc/S3JOb/0uHS71uxb28ErWw+dy8xs9J5bgD+Tbh6SQOKqncXRHZNRUwiFfsXcIaZZZpZM7Z3I5kFfGNm6cAFCdp2c+Abdy8BLiT0cyxSo5QgRCrg7h8S6hE+A/5BKA7aAPwX8D4hgXyZoM0/DlxsZp8CnYEfErQdkQqpuW+RSphZM3cvjO5UehsY7u4fJzsukZqgOgiRyo01sy5AJvCskoPUJ7qCEBGRuFQHISIicSlBiIhIXEoQIiISlxKEiIjEpQQhIiJxKUGIiEhc/x8Il3XUi9e6IwAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "#Least squares with cleaned data\n",
    "make_plots_gammas(mse_te_least_squares_GD_clean, gammas_lsgd_clean, \\\n",
    "                  \"raw_data_least_squares_GD_clean\", \"Least squares gradient descent cleaned data\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Logistic regression with cleaned data\n",
    "make_plots_gammas(losses_tr_logistic_regression_clean, losses_te_logistic_regression_clean, gammas_logistic_clean, \\\n",
    "                  \"raw_data_logistic_regression_clean\", \"Logistic regression cleaned data\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
