{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "# Useful starting lines\n",
    "%matplotlib inline\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load the training data into feature matrix, class labels, and event ids:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from proj1_helpers import *\n",
    "DATA_TRAIN_PATH = 'data/train.csv'\n",
    "y, tX, ids = load_csv_data(DATA_TRAIN_PATH)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Do your thing crazy machine learning thing here :) ..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from implementations import *\n",
    "\n",
    "# columns with problems : 2 6 7 8 14 25 26 27 28 29 30   (all -2 for tX)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1., 1., 1., 2., 1., 4., 1., 8.],\n",
       "       [1., 1., 1., 2., 1., 4., 1., 8.],\n",
       "       [1., 1., 1., 2., 1., 4., 1., 8.]])"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "expand_features_polynomial(np.array([[1,2],[1,2],[1,2]]), 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 1.          1.          1.         ...  2.87234595 -0.51553048\n",
      "   0.95579599]\n",
      " [ 1.          1.          1.         ...  1.62944412 -0.52872659\n",
      "   0.0680806 ]\n",
      " [ 1.          1.          1.         ...  2.89452861 -0.52872659\n",
      "   0.04201829]\n",
      " ...\n",
      " [ 1.          1.          1.         ...  2.08287559 -0.52872659\n",
      "   0.01220828]\n",
      " [ 1.          1.          1.         ...  0.94551622 -0.54192269\n",
      "  -0.54192269]\n",
      " [ 1.          1.          1.         ...  0.76983644 -0.54192269\n",
      "  -0.54192269]]\n",
      "[ 0.8007018  -2.92199351 -3.00253163 -2.50158859  6.12385299  4.96308226\n",
      "  6.13466306 -2.08166537 -2.28694903 -3.66649614 -2.07595131 -2.0466382\n",
      "  6.1309873  -2.37451567 -2.05474108 -2.05493338 -2.62028369 -2.05457273\n",
      " -2.05512509 -2.54594389 -2.05436537 -4.25165794 -2.06585248  3.14615146\n",
      "  3.58303722  3.58307888  5.92990739  6.13231249  6.13211937 -2.78134089]\n"
     ]
    }
   ],
   "source": [
    "tX_cleaned, _, _ = standardize(remove_wrong_columns(tX))\n",
    "degree = 1\n",
    "tX_expanded = expand_features_polynomial(tX_cleaned, degree)\n",
    "tX_stdrzed, _, _ = standardize(tX)\n",
    "\n",
    "lambda_ = 10000\n",
    "initial_w = np.array([1. for i in range(tX_stdrzed.shape[1])])\n",
    "gamma = 0.00001\n",
    "max_iters = 2000\n",
    "weights, loss = reg_logistic_regression(y, tX_stdrzed,lambda_, initial_w, max_iters, gamma)\n",
    "print(weights)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Generate predictions and save ouput in csv format for submission:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [],
   "source": [
    "DATA_TEST_PATH = 'data/test.csv'\n",
    "_, tX_test, ids_test = load_csv_data(DATA_TEST_PATH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {},
   "outputs": [],
   "source": [
    "tX_test_cleaned, _, _ = standardize(remove_wrong_columns(tX_test))\n",
    "tX_test_expanded = expand_features_polynomial(tX_test_cleaned, degree)\n",
    "tX_test_stdrzd, _, _ = standardize(tX_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {},
   "outputs": [],
   "source": [
    "OUTPUT_PATH = 'data/output.csv' \n",
    "y_pred = predict_labels(weights, tX_test_stdrzd)\n",
    "create_csv_submission(ids_test, y_pred, OUTPUT_PATH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4386.3529581824805"
      ]
     },
     "execution_count": 145,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "compute_loss(mse, y_pred, tX_test_stdrzd, weights)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Achieve 0.692 with\n",
    "```python\n",
    "tX_cleaned, _, _ = standardize(remove_wrong_columns(tX))\n",
    "degree = 1\n",
    "tX_expanded = expand_features_polynomial(tX_cleaned, degree)\n",
    "tX_stdrzed, _, _ = standardize(tX)\n",
    "\n",
    "lambda_ = 10000\n",
    "initial_w = np.array([1. for i in range(tX_stdrzed.shape[1])])\n",
    "gamma = 0.00001\n",
    "max_iters = 2000\n",
    "weights, loss = reg_logistic_regression(y, tX_stdrzed,lambda_, initial_w, max_iters, gamma)\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "file_extension": ".py",
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  },
  "mimetype": "text/x-python",
  "name": "python",
  "npconvert_exporter": "python",
  "pygments_lexer": "ipython3",
  "version": 3
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
