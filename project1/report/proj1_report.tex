\documentclass[11pt, a4paper, twoside]{article}
\usepackage[utf8]{inputenc}
\usepackage{graphicx}
\usepackage{listings}

 
\begin{document}
\date{2019 October}
\title{CS-443 Machine Learning Project 1: J-D-S Team}
\author{
  Julie Camille Rosalie Giunta\\
  \texttt{274957}
  \and
  Samuel Chassot\\
  \texttt{270955}
  \and
  Daniel Filipe Nunes Silva\\
  \texttt{275197}
}

\maketitle
\clearpage

\begin{abstract}
This is not an abstract.
\end{abstract}

\section{Introduction}
The goal of the project was to do classification on real data coming from CERN. To do so, we compared different methodology to understand the impact of cleaning the data, using different machine learning algorithms or cross-validation in order to tune the hyperparameters.

We had six algorithms at our disposal but we did most of the work with 
\begin{lstlisting}
least_squares_GD 
ridge_regression
logistic_regression
reg_logistic_regression
\end{lstlisting}
since the stochastic gradient descent was useful only if we did not want to go to harsh on our computers and that
\begin{lstlisting}
least_squares
\end{lstlisting}
gave a first result of 37\% accuracy on AIcrowd which was too far behind the other methods.
 
\section{other section}
This is not our report.

\section{Least squares gradient descent}
To test the efficiency of \textit{least_squares_GD} on our dataset, which we standardize, we use cross-validation with five sets to train the hyperparameter $\gamma$.
In figure~\ref{fig:lsgd}, you can observe how fast the cross-validation test error is growing when you change gamma from $0.08$ to $0.09$ but in order to have a more useful representation of the progression of the error, you can take a look at figure~\ref{fig:lsgd_useful}, which omits the error corresponding to $\gamma = 0.09$.
For the initial weights chosen, they are first all initialized to $0.5$. We then modify the initial weights it to be closer to the final weights we got. Surprisingly, $0.4$ gives a better accuracy result on AICrowd ($69.7\%$) than $0.0$ ($69.3\%$) which is closer to the final weights in general and ouputs a smaller loss.
For the number of iterations, $200$ and $1000$ converge almost to the same loss so to be more efficient, we choose $200$.
Our best submission with \textit{least_squares_GD} has an accuracy of $69.7\%$ and has, as hyperparameters,
\begin{lstlisting}
max_iters = 200
k_fold = 5
initial_weights = np.array([0.4 for i in range(tX_stdrzed.shape[1])])
gamma = 0.08
\end{lstlisting}

\begin{figure}
    \includegraphics[width= 3, height = 3]{raw_data_least_squares_GD.png}
    \label{fig:lsgd}
\end{figure}

\begin{figure}
    \includegraphics[width= 3, height = 3]{raw_data_least_squares_GD_useful.png}
    \label{fig:lsgd_useful}
\end{figure}

\section{Logistic regression}
We also used cross-validation to test the efficiency of \textit{logistic_regression} on our standardized dataset.
We use five sets to set the hyperparameter $\gamma$.
For the initial weights chosen, they are all initialized to $0.5$ since $0.0, 0.1, ..., 0.6$ do not change the loss a lot but worsen the accuracy on AICrowd.
Our best submission with \textit{logistic_regression} had an accuracy of $73.9\%$ and had 
\begin{lstlisting}
max_iters = 1000
k_fold = 5
initial_weights = np.array([0.5 for i in range(tX_stdrzed.shape[1])])
gamma = 1e-06
\end{lstlisting}

\begin{figure}
    \includegraphics[width= 3, height = 3]{raw_data_logistic_regression.png}
    \label{fig:log_reg}
\end{figure}

\end{document}