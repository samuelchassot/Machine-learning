\documentclass[11pt, a4paper, twocolumn]{article}
\usepackage[utf8]{inputenc}
\usepackage{graphicx}
\usepackage{listings}
\usepackage{amsmath,amsfonts,amssymb}
\usepackage{geometry}
 \geometry{
 left=20mm,
 right=20mm,
 top=20mm,
 bottom=20mm
 }

\graphicspath{ {./plots/} }

\begin{document}
\date{2019 October}
\title{CS-443 Machine Learning Project 1: J-D-S Team}
\author{
  Julie Camille Rosalie Giunta\\
  \texttt{274957}
  \and
  Samuel Chassot\\
  \texttt{270955}
  \and
  Daniel Filipe Nunes Silva\\
  \texttt{275197}
}

\maketitle
\clearpage

\section{Introduction}
The goal of this project is to apply machine learning
methods learned in class on a real dataset. We take a
strong interest in testing a lot of techniques and
comparing their results. This comparison encourage us to
tweak hyperparameters and check their effectiveness using cross-validation.

We do not use least\_squares\_SGD because we do not want
to trade precision for time. We consider
that it would provide us results close to
least\_squares\_GD we already use. Finally, we assess the following
methods:

\begin{itemize}
  \setlength{\itemsep}{1pt}
  \setlength{\parskip}{0pt}
  \setlength{\parsep}{0pt}
  \item least\_squares
  \item least\_squares\_GD 
  \item ridge\_regression
  \item logistic\_regression
  \item reg\_logistic\_regression
\end{itemize}

\section{Cleaning the data}
To clean the data, we remove the features
that contain $-999.0$ from the training and testing sets. 
Since they are the same features in both sets, 
the weights we obtained from training can be used for testing.

\section{Least squares}
This method is the simplest to implement but does not
provide us robust results. With a score of 37\% on
AICrowd, this is worse than tossing a coin as it predicts -1 for every sample. 

\section{Least squares gradient descent}
We use 5 folds cross-validation
to train the hyper parameter gamma.
For the initial weights chosen, they are first all initialized to $0.5$ and then set to $0.4$ 
since it gives a better accuracy result on AICrowd.
We do $200$ iterations since the loss stagnates after.
Figure \ref{fig:lsgd}, 
represents the fast growing of error 
when you change gamma from $0.08$ to $0.09$ .
Figure \ref{fig:raw_clean_lsgd} omits the error corresponding to $gamma = 0.09$ for the raw data.
Our best submission with \textit{least\_squares\_GD} using raw data 
has an accuracy of $69.7\%$ and has, as hyperparameters,
\begin{lstlisting}
  max_iters = 200
  k_fold = 5
  initial_weights = [0.4, ..., 0.4]
  gamma = 0.08
\end{lstlisting}
With cleaned data (red line in figure \ref{fig:raw_clean_lsgd}), 
the best submission has $72\%$ and use $gamma = 0.12$.

\begin{figure}[h!]
  \includegraphics[width=\linewidth]{raw_data_least_squares_GD.png}
  \caption{Linear regression gradient descent}
  \label{fig:lsgd}
\end{figure}
\begin{figure}[h!]
  \includegraphics[width=\linewidth]{raw_vs_clean_lsgd.png}
  \caption{Raw/cleaned data for LSGD}
    \label{fig:raw_clean_lsgd}
\end{figure}

\section{Ridge regression}
We first train our ridge regression model on raw data by
expanding its features polynomially for degrees from 1 up
to 15 and lambdas on a
logarithmic scale from $10^{-30}$ to
$10^0$ sampled at 50 points. Using 5-folds cross validation, we deduce that
polynomials of smaller degrees may underfit the data as
the models better fit the data with the smaller lambdas.
On the other hand, using polynomials of degree higher than
7 shows unconsistent and unrobust results. The train error
is minimized using bigger lambdas, which may explain an
overfitting behaviour. The sweet spot
seems to be around degree 5 even if on
the local dataset, the results are very
close  as shown in figure
\ref{fig:ridge_raw}. As shown in figure
\ref{fig:ridge_clean}, cleaning the data
gives us slightly better results. The used
parameters for the best score on AICrowd (76.5\%)
as well as in the run.py are shown in
\ref{fig:ridge_clean} by a light blue
point.

\begin{figure}[h!]
  \includegraphics[width=\linewidth]{plots/ridge_raw.png}
  \caption{Ridge regression on raw data}
  \label{fig:ridge_raw}
\end{figure}

\begin{figure}[h!]
  \includegraphics[width=\linewidth]{plots/ridge_clean.png}
  \caption{Ridge regression on raw data}
  \label{fig:ridge_clean}
\end{figure}

\section{Logistic regression}
We use five sets to set the hyperparameter gamma.
For the initial weights chosen, they are all initialized to $0.5$ since $0.0, 0.1, ..., 0.6$ do not change the loss a lot but worsen the accuracy on AICrowd.
Our best submission with raw data had an accuracy of $73.9\%$ and had 
\begin{lstlisting}
  max_iters = 1000
  k_fold = 5
  initial_weights = [0.5, ..., 0.5]
  gamma = 1e-6
\end{lstlisting}
With cleaned data, the best submission has $72.7\%$ and use $gamma = 10^{-6}$.
You can observe both in figure \ref{fig:raw_clean_log_reg}.

\begin{figure}[h!]
  \includegraphics[width=\linewidth]{raw_vs_clean_log_reg.png}
  \caption{Raw/cleaned data for logistic regression}
  \label{fig:raw_clean_log_reg}
\end{figure}

\newpage
\section{Regularized logistic regression}
We implement cross-validation to optimize the values of lambda and gamma. lambda takes values
$\{1,10,100,1000,10000\}$ and gamma takes values $\{10^{-6},10^{-7},10^{-8},10^{-9}\}$. Taking bigger
values for gamma results in the loss taking value $nan$. You can see the test error plotted against lambda in figure \ref{fig:raw_reg_log_regr}. Other parameters are: 
\begin{lstlisting}
  max_iters = 3000
  k_fold = 3
  w_initial_raw = [0.0, ..., 0.0]
\end{lstlisting}

This outputs the values for lambda and gamma that minimize the test error. These values are:
$lambda = 10$ and $gamma = 10^{-6}$.\\
Then we run the regularized logistic regression algorithm on the whole training set with these two values for hyper parameters but with $max\_iters = 30000$ to obtain a good $w$ vector.

The best score on AICrowd achieved using this technique on raw data is 73.7\%. Using cleaned data, we achieve 72.5\%.
\begin{figure}[h!]
  \includegraphics[width=\linewidth]{plots/raw_data_reg_log_regr.png}
  \caption{Regularized logistic regression - HP optimization}
  \label{fig:raw_reg_log_regr}
\end{figure}

\end{document}

