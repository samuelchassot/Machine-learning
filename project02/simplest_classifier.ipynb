{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "DATASET_PATH      = \"Datasets/\"\n",
    "DATASET_PATH_MORE = \"twitter-datasets/\"\n",
    "\n",
    "POS_DATASET  = \"train_pos\"\n",
    "NEG_DATASET  = \"train_neg\"\n",
    "\n",
    "FULL_DATASETS_EXT = \"_full\"\n",
    "EXT = \".txt\"\n",
    "\n",
    "TEST_FILE_ORIGINAL = \"test_data.txt\"\n",
    "\n",
    "SUBMISSION_FILE = \"submission.csv\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "pos_words_count = {}\n",
    "pos_words_set   = set([])\n",
    "\n",
    "with open(DATASET_PATH+DATASET_PATH_MORE+POS_DATASET+FULL_DATASETS_EXT+EXT, \"r\") as pd:\n",
    "    for line in pd:\n",
    "        for word in line.split(\" \"):\n",
    "            if word in pos_words_count:\n",
    "                pos_words_count[word] += 1\n",
    "            else:\n",
    "                pos_words_count[word]  = 1\n",
    "                pos_words_set.add(word)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "neg_words_count = {}\n",
    "neg_words_set   = set([])\n",
    "\n",
    "with open(DATASET_PATH+DATASET_PATH_MORE+NEG_DATASET+FULL_DATASETS_EXT+EXT, \"r\") as nd:\n",
    "    for line in nd:\n",
    "        for word in line.split(\" \"):\n",
    "            if word in neg_words_count:\n",
    "                neg_words_count[word] += 1\n",
    "            else:\n",
    "                neg_words_count[word]  = 1\n",
    "                neg_words_set.add(word)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "intersection = pos_words_set.intersection(neg_words_set)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "for w in intersection:\n",
    "    if pos_words_count[w] >= neg_words_count[w]:\n",
    "        del(neg_words_count[w])\n",
    "    else:\n",
    "        del(pos_words_count[w])    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "pos_words = dict([(k, v) for k,v in pos_words_count.items()])\n",
    "neg_words = dict([(k,-v) for k,v in neg_words_count.items()])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(DATASET_PATH+TEST_FILE_ORIGINAL, \"r\") as tff:\n",
    "    with open(DATASET_PATH+SUBMISSION_FILE, \"w\") as sf:\n",
    "        sf.write(\"Id,Prediction\\n\")\n",
    "        c = 1\n",
    "        for line in tff:\n",
    "            line_score = 0\n",
    "            for word in \",\".join(line.split(\",\")[1:]).split(\" \"):\n",
    "                if word in pos_words:\n",
    "                    line_score += 1\n",
    "                elif word in neg_words:\n",
    "                    line_score -= 1\n",
    "            sf.write(\"{},{}\\n\".format(c,1 if line_score > 0 else -1))\n",
    "            c += 1"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
