{
 "nbformat": 4,
 "nbformat_minor": 2,
 "metadata": {
  "language_info": {
   "name": "python",
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "version": "3.7.3"
  },
  "orig_nbformat": 2,
  "file_extension": ".py",
  "mimetype": "text/x-python",
  "name": "python",
  "npconvert_exporter": "python",
  "pygments_lexer": "ipython3",
  "version": 3
 },
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import fasttext as ft"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = np.load(\"tweets_X_sam.npy\")\n",
    "y = np.load(\"tweets_y_sam.npy\")\n",
    "\n",
    "j = 0.8\n",
    "\n",
    "train_X = X[0:int(j*len(y))]\n",
    "train_y = y[0:int(j*len(y))]\n",
    "test_X = X[int(j*len(y)):]\n",
    "test_y = y[int(j*len(y)):]\n",
    "\n",
    "train_y[train_y == -1.] = 0.\n",
    "test_y[test_y == -1.] = 0."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset = tf.data.Dataset.from_tensor_slices((train_X, train_y))\n",
    "test_dataset = tf.data.Dataset.from_tensor_slices((test_X, test_y))\n",
    "\n",
    "BATCH_SIZE = 64\n",
    "SHUFFLE_BUFFER_SIZE = 100\n",
    "\n",
    "train_dataset = train_dataset.shuffle(SHUFFLE_BUFFER_SIZE).batch(BATCH_SIZE)\n",
    "test_dataset = test_dataset.batch(BATCH_SIZE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = tf.keras.Sequential([\n",
    "    tf.keras.layers.Dense(250, activation='relu'),\n",
    "    tf.keras.layers.Dense(20, activation='softmax')\n",
    "    #tf.keras.layers.Dense(50, activation='relu'),\n",
    "    #tf.keras.layers.Dense(10, activation='softmax'),\n",
    "])\n",
    "\n",
    "model.compile(optimizer=tf.keras.optimizers.RMSprop(),\n",
    "                loss=tf.keras.losses.SparseCategoricalCrossentropy(),\n",
    "                metrics=[tf.keras.metrics.SparseCategoricalAccuracy()])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": "WARNING:tensorflow:Layer sequential_10 is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because it's dtype defaults to floatx.\n\nIf you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n\nTo change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n\nEpoch 1/15\n2500/2500 [==============================] - 10s 4ms/step - loss: 0.6495 - sparse_categorical_accuracy: 0.6164\nEpoch 2/15\n2500/2500 [==============================] - 6s 2ms/step - loss: 0.5826 - sparse_categorical_accuracy: 0.6760\nEpoch 3/15\n2500/2500 [==============================] - 5s 2ms/step - loss: 0.5495 - sparse_categorical_accuracy: 0.7039\nEpoch 4/15\n2500/2500 [==============================] - 5s 2ms/step - loss: 0.5265 - sparse_categorical_accuracy: 0.7218\nEpoch 5/15\n2500/2500 [==============================] - 5s 2ms/step - loss: 0.5070 - sparse_categorical_accuracy: 0.7370\nEpoch 6/15\n2500/2500 [==============================] - 5s 2ms/step - loss: 0.4898 - sparse_categorical_accuracy: 0.7485\nEpoch 7/15\n2500/2500 [==============================] - 5s 2ms/step - loss: 0.4743 - sparse_categorical_accuracy: 0.7588\nEpoch 8/15\n2500/2500 [==============================] - 5s 2ms/step - loss: 0.4602 - sparse_categorical_accuracy: 0.7689\nEpoch 9/15\n2500/2500 [==============================] - 5s 2ms/step - loss: 0.4474 - sparse_categorical_accuracy: 0.7759\nEpoch 10/15\n2500/2500 [==============================] - 5s 2ms/step - loss: 0.4353 - sparse_categorical_accuracy: 0.7844\nEpoch 11/15\n2500/2500 [==============================] - 5s 2ms/step - loss: 0.4246 - sparse_categorical_accuracy: 0.7907\nEpoch 12/15\n2500/2500 [==============================] - 5s 2ms/step - loss: 0.4152 - sparse_categorical_accuracy: 0.7963\nEpoch 13/15\n2500/2500 [==============================] - 5s 2ms/step - loss: 0.4055 - sparse_categorical_accuracy: 0.8018\nEpoch 14/15\n2500/2500 [==============================] - 5s 2ms/step - loss: 0.3972 - sparse_categorical_accuracy: 0.8065\nEpoch 15/15\n2500/2500 [==============================] - 5s 2ms/step - loss: 0.3884 - sparse_categorical_accuracy: 0.8119\n"
    },
    {
     "data": {
      "text/plain": "<tensorflow.python.keras.callbacks.History at 0x64ebd3828>"
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(train_dataset, epochs=15)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": "625/625 [==============================] - 1s 1ms/step - loss: 0.8010 - sparse_categorical_accuracy: 0.6836\n"
    },
    {
     "data": {
      "text/plain": "[0.8010182406425476, 0.6836]"
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.evaluate(test_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "fout = open(\"train_supervised.txt\", \"w\")\n",
    "fout2 = open(\"test_supervised.txt\", \"w\")\n",
    "f1 = open(\"Datasets/twitter-datasets/train_pos.txt\", \"r\")\n",
    "f2 = open(\"Datasets/twitter-datasets/train_neg.txt\", \"r\")\n",
    "\n",
    "i = 0\n",
    "for l in f1.readlines():\n",
    "    fout.write(\"__label__positive \" + l)\n",
    "    if i > 80000:\n",
    "        fout2.write(\"__label__positive \" + l)\n",
    "    i += 1\n",
    "i = 0\n",
    "for l in f2.readlines():\n",
    "    fout.write(\"__label__negative \" + l)\n",
    "    if i > 80000:\n",
    "        fout2.write(\"__label__positive \" + l)\n",
    "    i+=1\n",
    "f1.close()\n",
    "f2.close()\n",
    "fout.close()\n",
    "fout2.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = ft.train_supervised('train_supervised.txt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": "['__label__negative', '__label__positive']"
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": "(('__label__positive',), array([0.99981397]))"
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.predict(\"hi all, thank you for everything bitch!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": "(39998, 0.5189259462973148, 0.5189259462973148)"
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.test(\"test_supervised.txt\", k=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": "array([ 0.02571399,  0.15396671,  0.04118297, -0.21249573,  0.10300473,\n        0.0679355 , -0.09303714,  0.02835391,  0.16474135,  0.16493794,\n       -0.02768764, -0.07995272, -0.09622344,  0.09716307, -0.09126273,\n       -0.06234534,  0.08886703,  0.18623899, -0.15840052, -0.04535728,\n       -0.09760258,  0.15655494,  0.04274376,  0.0777818 , -0.04115377,\n       -0.20150737, -0.09738524, -0.11599219, -0.17654024,  0.15988488,\n       -0.17184366,  0.10775842, -0.09421516, -0.13489622, -0.27430215,\n       -0.08880118, -0.08983865, -0.0888577 ,  0.06397012, -0.01490111,\n       -0.07386695,  0.31255385,  0.06257832,  0.11577053,  0.13096482,\n       -0.05254146,  0.12596858, -0.10450681, -0.10654113,  0.24910197,\n       -0.12927958,  0.18731278, -0.11526599,  0.14024238, -0.14922841,\n        0.03247508, -0.18863636, -0.09864707,  0.10644189, -0.02615612,\n        0.00728449,  0.10776213,  0.15437657,  0.13160653, -0.01349203,\n       -0.09614967, -0.20270133, -0.02062804,  0.00064062, -0.10408647,\n       -0.17305616,  0.05169189, -0.00253879, -0.11106369, -0.07887001,\n       -0.02449477,  0.10974195,  0.03889515,  0.07962251, -0.01062912,\n       -0.0471232 ,  0.01600969,  0.10940198, -0.00197577,  0.08182845,\n       -0.08995222,  0.15674609, -0.04327465, -0.01629959, -0.07260174,\n        0.19479792,  0.00125491,  0.207558  , -0.02646345,  0.1441111 ,\n        0.01169929,  0.00484121,  0.13533713, -0.05212374, -0.02553489],\n      dtype=float32)"
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ]
}